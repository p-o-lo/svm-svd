{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paolo/.local/lib/python3.6/site-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.manifold.t_sne module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.manifold. Anything that cannot be imported from sklearn.manifold is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import math\n",
    "import scipy.spatial.distance as scpd\n",
    "from scipy import linalg\n",
    "from sklearn.manifold.t_sne import _joint_probabilities\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.spatial.distance import squareform\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from IPython import get_ipython\n",
    "get_ipython().run_line_magic('matplotlib', 'qt')\n",
    "\n",
    "f = h5py.File(\"NLO_3B_for_singV.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = f['alphas'][:]\n",
    "np.savetxt('alphas_3_plot.out', alphas, delimiter='   ')\n",
    "alphas.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x7f9db40dc160>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(alphas[:,0],alphas[:,1],alphas[:,2], c=np.arange(100), marker='o')\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(alphas[:,0],alphas[:,1],alphas[:,2],marker='o')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2\n",
    "perplexity = 0.01\n",
    "MACHINE_EPSILON = np.finfo(np.double).eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(X):\n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    # Compute euclidean distance\n",
    "    distances = pairwise_distances(X, metric='euclidean', squared=True)\n",
    "    \n",
    "    # Compute joint probabilities p_ij from distances.\n",
    "    P = _joint_probabilities(distances=distances, desired_perplexity=perplexity, verbose=False)\n",
    "    \n",
    "    # The embedding is initialized with iid samples from Gaussians with standard deviation 1e-4.\n",
    "    X_embedded = 1e-4 * np.random.mtrand._rand.randn(n_samples, n_components).astype(np.float32)\n",
    "    \n",
    "    # degrees_of_freedom = n_components - 1 comes from\n",
    "    # \"Learning a Parametric Embedding by Preserving Local Structure\"\n",
    "    # Laurens van der Maaten, 2009.\n",
    "    degrees_of_freedom = max(n_components - 1, 1)\n",
    "    \n",
    "    return _tsne(P, degrees_of_freedom, n_samples, X_embedded=X_embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _kl_divergence(params, P, degrees_of_freedom, n_samples, n_components):\n",
    "    X_embedded = params.reshape(n_samples, n_components)\n",
    "    \n",
    "    dist = pdist(X_embedded, \"sqeuclidean\")\n",
    "    dist /= degrees_of_freedom\n",
    "    dist += 1.\n",
    "    dist **= (degrees_of_freedom + 1.0) / -2.0\n",
    "    Q = np.maximum(dist / (2.0 * np.sum(dist)), MACHINE_EPSILON)\n",
    "    \n",
    "    # Kullback-Leibler divergence of P and Q\n",
    "    kl_divergence = 2.0 * np.dot(P, np.log(np.maximum(P, MACHINE_EPSILON) / Q))\n",
    "    \n",
    "    # Gradient: dC/dY\n",
    "    grad = np.ndarray((n_samples, n_components), dtype=params.dtype)\n",
    "    PQd = squareform((P - Q) * dist)\n",
    "    for i in range(n_samples):\n",
    "        grad[i] = np.dot(np.ravel(PQd[i], order='K'),\n",
    "                         X_embedded[i] - X_embedded)\n",
    "    grad = grad.ravel()\n",
    "    c = 2.0 * (degrees_of_freedom + 1.0) / degrees_of_freedom\n",
    "    grad *= c\n",
    "    \n",
    "    return kl_divergence, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tsne(P, degrees_of_freedom, n_samples, X_embedded):\n",
    "    \n",
    "    params = X_embedded.ravel()\n",
    "    \n",
    "    obj_func = _kl_divergence\n",
    "    \n",
    "    params = _gradient_descent(obj_func, params, [P, degrees_of_freedom, n_samples, n_components])\n",
    "        \n",
    "    X_embedded = params.reshape(n_samples, n_components)\n",
    "    \n",
    "    return X_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _gradient_descent(obj_func, p0, args, it=0, n_iter=1000,\n",
    "                      n_iter_check=1, n_iter_without_progress=300,\n",
    "                      momentum=0.8, learning_rate=200.0, min_gain=0.01,\n",
    "                      min_grad_norm=1e-7):\n",
    "    \n",
    "    p = p0.copy().ravel()\n",
    "    update = np.zeros_like(p)\n",
    "    gains = np.ones_like(p)\n",
    "    error = np.finfo(np.float).max\n",
    "    best_error = np.finfo(np.float).max\n",
    "    best_iter = i = it\n",
    "    \n",
    "    for i in range(it, n_iter):\n",
    "        error, grad = obj_func(p, *args)\n",
    "        grad_norm = linalg.norm(grad)\n",
    "        inc = update * grad < 0.0\n",
    "        dec = np.invert(inc)\n",
    "        gains[inc] += 0.2\n",
    "        gains[dec] *= 0.8\n",
    "        np.clip(gains, min_gain, np.inf, out=gains)\n",
    "        grad *= gains\n",
    "        update = momentum * update - learning_rate * grad\n",
    "        p += update\n",
    "        \n",
    "        print(\"[t-SNE] Iteration %d: error = %.7f,\"\n",
    "                      \" gradient norm = %.7f\"\n",
    "                      % (i + 1, error, grad_norm))\n",
    "        \n",
    "        if error < best_error:\n",
    "                best_error = error\n",
    "                best_iter = i\n",
    "        elif i - best_iter > n_iter_without_progress:\n",
    "            break\n",
    "        \n",
    "        if grad_norm <= min_grad_norm:\n",
    "            break\n",
    "            \n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t-SNE] Iteration 1: error = 4.3072240, gradient norm = 0.0000503\n"
     ]
    }
   ],
   "source": [
    "X_embedded = fit(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f9da88060f0>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.plot(X_embedded[:,0], X_embedded[:,1],'o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
